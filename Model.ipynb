{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "data1 = unpickle(\"./input/data_batch_1\")\n",
    "data2 = unpickle(\"./input/data_batch_2\")\n",
    "data3 = unpickle(\"./input/data_batch_3\")\n",
    "data4 = unpickle(\"./input/data_batch_4\")\n",
    "data5 = unpickle(\"./input/data_batch_5\")\n",
    "label_data = unpickle('./input/batches.meta')[b'label_names']\n",
    "\n",
    "labels1 = data1[b'labels']\n",
    "data1 = data1[b'data'] * 1.0\n",
    "labels2 = data2[b'labels']\n",
    "data2 = data2[b'data'] * 1.0\n",
    "labels3 = data3[b'labels']\n",
    "data3 = data3[b'data'] * 1.0\n",
    "labels4 = data4[b'labels']\n",
    "data4 = data4[b'data']  * 1.0\n",
    "labels5 = data5[b'labels']\n",
    "data5 = data5[b'data']  * 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the remaining four arrays to use as training data\n",
    "X_tr = np.concatenate([data1, data2, data3, data4, data5], axis=0)\n",
    "X_tr = np.dstack((X_tr[:, :1024], X_tr[:, 1024:2048], X_tr[:, 2048:])) / 1.0\n",
    "X_tr = (X_tr - 128) / 255.0\n",
    "X_tr = X_tr.reshape(-1, 32, 32, 3)\n",
    "\n",
    "y_tr = np.concatenate([labels1, labels2, labels3, labels4, labels5], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr (50000, 32, 32, 3)\n",
      "y_tr (50000,)\n"
     ]
    }
   ],
   "source": [
    "# set number of classes\n",
    "num_classes = len(np.unique(y_tr))\n",
    "\n",
    "print(\"X_tr\", X_tr.shape)\n",
    "print(\"y_tr\", y_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the test data\n",
    "test_data = unpickle(\"./input/test_batch\")\n",
    "\n",
    "X_test = test_data[b'data']\n",
    "X_test = np.dstack((X_test[:, :1024], X_test[:, 1024:2048], X_test[:, 2048:])) / 1.0\n",
    "X_test = (X_test - 128) / 255.0\n",
    "X_test = X_test.reshape(-1, 32, 32, 3)\n",
    "y_test = np.asarray(test_data[b'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_te (5000, 32, 32, 3)\n",
      "X_cv (5000, 32, 32, 3)\n",
      "y_te (5000,)\n",
      "y_cv (5000,)\n"
     ]
    }
   ],
   "source": [
    "# split into test and validation\n",
    "X_te, X_cv, y_te, y_cv = train_test_split(X_test, y_test, test_size=0.5, random_state=1)\n",
    "\n",
    "print(\"X_te\", X_te.shape)\n",
    "print(\"X_cv\", X_cv.shape)\n",
    "print(\"y_te\", y_te.shape)\n",
    "print(\"y_cv\", y_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch generator\n",
    "def get_batches(X, y, batch_size, crop=False, distort=True):\n",
    "    # Shuffle X,y\n",
    "    shuffled_idx = np.arange(len(y))\n",
    "    np.random.shuffle(shuffled_idx)\n",
    "    i, h, w, c = X.shape\n",
    "    \n",
    "    # Enumerate indexes by steps of batch_size\n",
    "    for i in range(0, len(y), batch_size):\n",
    "        batch_idx = shuffled_idx[i:i+batch_size]\n",
    "        X_return = X[batch_idx]\n",
    "        \n",
    "        # optional random crop of images\n",
    "        if crop:\n",
    "            woff = (w - 24) // 4\n",
    "            hoff = (h - 24) // 4\n",
    "            startw = np.random.randint(low=woff,high=woff*2)\n",
    "            starth = np.random.randint(low=hoff,high=hoff*2)\n",
    "            X_return = X_return[:,startw:startw+24,starth:starth+24,:]\n",
    "       \n",
    "        # do random flipping of images\n",
    "        coin = np.random.binomial(1, 0.5, size=None)\n",
    "        if coin and distort:\n",
    "            X_return = X_return[...,::-1,:]\n",
    "        \n",
    "        yield X_return, y[batch_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "epochs = 3                   # how many epochs\n",
    "batch_size = 128\n",
    "steps_per_epoch = X_tr.shape[0] / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "\n",
    "\n",
    "class MiniVGGNet:\n",
    "    def build(width, height, depth, classes):\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1\n",
    "        dataFormat = 'channels_last'\n",
    "        \n",
    "        if K.image_data_format()=='channels_first':\n",
    "            inputShape = (depth, height, width)\n",
    "            chanDim = 1\n",
    "            dataFormat = 'channels_first'\n",
    "        \n",
    "        model.add(Conv2D(filters = 32, kernel_size = (3,3), padding = 'same', input_shape = inputShape))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(filters = 32, kernel_size = (3,3), padding = 'same', input_shape = inputShape))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(axis = chanDim))\n",
    "        model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2), data_format = dataFormat))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', input_shape = inputShape))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', input_shape = inputShape))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(axis = chanDim))\n",
    "        model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2), data_format = dataFormat))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(axis = -1))\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation('softmax'))\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "X_train = X_tr.astype('float')/255.0\n",
    "X_test = X_te.astype('float')/255.0\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_tr)\n",
    "y_test = lb.transform(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "aug = ImageDataGenerator(rotation_range=30, horizontal_flip=True, width_shift_range=0.1, height_shift_range=0.1,\n",
    "                         shear_range=0.2, fill_mode='nearest', vertical_flip=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
